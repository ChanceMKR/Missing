{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cpu\n",
      "인물(클래스) 목록: ['김시현', '김지연', '서예은', '윤다영', '임혜영']\n",
      "\n",
      "Epoch [1/5]\n",
      "  [Train] Loss: 0.1770  Acc: 0.9571\n",
      "  [Val]   Loss: 0.1638  Acc: 0.9400\n",
      "  >> Best model saved!\n",
      "\n",
      "Epoch [2/5]\n",
      "  [Train] Loss: 0.0521  Acc: 0.9856\n",
      "  [Val]   Loss: 0.0638  Acc: 0.9865\n",
      "  >> Best model saved!\n",
      "\n",
      "Epoch [3/5]\n",
      "  [Train] Loss: 0.0759  Acc: 0.9819\n",
      "  [Val]   Loss: 0.3362  Acc: 0.9240\n",
      "\n",
      "Epoch [4/5]\n",
      "  [Train] Loss: 0.0489  Acc: 0.9859\n",
      "  [Val]   Loss: 0.1845  Acc: 0.9755\n",
      "\n",
      "Epoch [5/5]\n",
      "  [Train] Loss: 0.0425  Acc: 0.9877\n",
      "  [Val]   Loss: 0.0731  Acc: 0.9792\n",
      "\n",
      "최고 검증 정확도: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArcFaceClassifier(\n",
       "  (backbone): IResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "    (layer1): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0, inplace=True)\n",
       "    (fc): Linear(in_features=25088, out_features=512, bias=True)\n",
       "    (features): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import warnings\n",
    "\n",
    "# 모든 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "############################################\n",
    "# (1) arcface_torch 백본 import\n",
    "############################################\n",
    "# InsightFace의 arcface_torch/backbones/ 폴더를 path에 추가 (필요 시 경로 수정)\n",
    "sys.path.append('insightface/recognition/arcface_torch/backbones')\n",
    "from iresnet import iresnet50  # iresnet100 등도 가능\n",
    "\n",
    "############################################\n",
    "# 2. 하이퍼파라미터 & 디바이스 설정\n",
    "############################################\n",
    "data_dir = 'data/faces'     # 얼굴 이미지를 폴더 구조로 저장한 경로\n",
    "backbone_path = 'weights/backbone.pth'  # 사전 학습된 ArcFace 백본 가중치\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용 디바이스:\", device)\n",
    "\n",
    "############################################\n",
    "# 3. 전처리 (ArcFace 표준: 112×112 사용)\n",
    "############################################\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    # ArcFace/InsightFace 백본은 보통 BGR -> [ -1~1 ] 정규화 등을 사용하지만,\n",
    "    # PyTorch에서는 RGB 순으로 읽으므로, 아래와 같은 정규화를 적용하는 경우가 많습니다.\n",
    "    # (중요) pretrained 모델마다 요구되는 Normalize가 다를 수 있으니, 모델에 맞춰 조정하세요.\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "############################################\n",
    "# 4. 데이터셋 (ImageFolder) & DataLoader\n",
    "############################################\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"인물(클래스) 목록:\", class_names)\n",
    "\n",
    "# (선택) Train/Val 분할\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "############################################\n",
    "# 5. ArcFace 백본(iResNet50) 불러오기\n",
    "############################################\n",
    "# iresnet50(pretrained=False) 로드 후, 사전 학습된 backbone.pth를 가져옴\n",
    "arcface_backbone = iresnet50(pretrained=False, fp16=False)  # fp16=True 시 half precision\n",
    "state_dict = torch.load(backbone_path, map_location='cpu')\n",
    "arcface_backbone.load_state_dict(state_dict)\n",
    "arcface_backbone.to(device)\n",
    "\n",
    "# (옵션) 백본 완전 동결(freeze)하고 싶다면\n",
    "# for param in arcface_backbone.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# iResNet50은 입력(112×112) -> 출력(512차원 임베딩)이 기본\n",
    "embedding_size = 512\n",
    "\n",
    "############################################\n",
    "# 6. 분류기(Linear) 얹기\n",
    "############################################\n",
    "class ArcFaceClassifier(nn.Module):\n",
    "    def __init__(self, backbone, embedding_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        # 여기서는 ArcFace의 마지막 'FC'가 아니라 임베딩만 추출하도록 사용하므로,\n",
    "        # 분류 용도로 새 Linear Layer를 붙임\n",
    "        self.classifier = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 3, 112, 112]\n",
    "        emb = self.backbone.forward(x)   # [B, 512] 임베딩\n",
    "        out = self.classifier(emb)       # [B, num_classes]\n",
    "        return out\n",
    "\n",
    "model = ArcFaceClassifier(arcface_backbone, embedding_size, num_classes).to(device)\n",
    "\n",
    "############################################\n",
    "# 7. 손실 함수 & 옵티마이저\n",
    "############################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "############################################\n",
    "# 8. 학습 함수 정의\n",
    "############################################\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "        # ---------- [Train] ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)         # 분류 결과 [B, num_classes]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "            train_correct += torch.sum(preds == labels)\n",
    "\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "\n",
    "        # ---------- [Validation] ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                val_correct += torch.sum(preds == labels)\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"  [Train] Loss: {epoch_train_loss:.4f}  Acc: {epoch_train_acc:.4f}\")\n",
    "        print(f\"  [Val]   Loss: {epoch_val_loss:.4f}  Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "        # 최고 정확도 업데이트 시 모델 저장\n",
    "        if epoch_val_acc > best_acc:\n",
    "            best_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), \"best_arcface_finetune.pt\")\n",
    "            print(\"  >> Best model saved!\")\n",
    "\n",
    "    print(f\"\\n최고 검증 정확도: {best_acc:.4f}\")\n",
    "\n",
    "############################################\n",
    "# 9. 학습 실행\n",
    "############################################\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs)\n",
    "\n",
    "############################################\n",
    "# 10. 추론(Inference) 함수\n",
    "############################################\n",
    "def predict_image(model, image_path, transform, class_names):\n",
    "    from PIL import Image\n",
    "\n",
    "    model.eval()\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)  # [1, 3, 112, 112]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    return class_names[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/Users/chance/Desktop/Project/missing/data/faces/김시현/face_873.jpg' 예측 결과: 김시현\n"
     ]
    }
   ],
   "source": [
    "# 추론 예시\n",
    "model.load_state_dict(torch.load(\"best_arcface_finetune.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_path = \"/Users/chance/Desktop/Project/missing/data/faces/김시현/face_873.jpg\"  # 이미 얼굴만 잘려진(112×112 혹은 비슷) 테스트 이미지\n",
    "pred_class = predict_image(model, test_path, transform, class_names)\n",
    "print(f\"'{test_path}' 예측 결과: {pred_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
